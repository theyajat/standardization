## What is Standardization
Standardization in machine learning refers to the process of transforming data so that it has a mean of zero and a standard deviation of one. This means that the data is scaled and centered around zero, with a consistent spread.

In simpler terms, standardization ensures that all the features or variables used in a machine learning model are on the same scale. This is important because many machine learning algorithms perform better when the input features are standardized, as it helps them converge faster and make fair comparisons between different features.

For example, if you're predicting housing prices and your features include square footage and number of bedrooms, standardization ensures that the impact of each feature on the prediction is measured consistently, regardless of their original units or scales.

Overall, standardization is a fundamental preprocessing step in machine learning that improves the performance and reliability of models.
